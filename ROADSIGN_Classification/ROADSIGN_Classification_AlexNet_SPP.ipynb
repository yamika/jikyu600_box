{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from load_dataset_AlexNet import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load label : Done!\n",
      "Load img : Done!\n",
      "Load label : Done!\n",
      "Load img : Done!\n"
     ]
    }
   ],
   "source": [
    "x_train,t_train = load_dataset('./train_dataset_AlexNet',convert_type='RGB',flatten=True,normalize=True,one_hot_label=True)\n",
    "x_test,t_test = load_dataset('./test_dataset_AlexNet',convert_type='RGB',flatten=True,normalize=True,one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 224*224*3],name=\"input\")\n",
    "t = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "### 入力層\n",
    "input_layer = tf.reshape(X, [-1,224,224,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 畳込み層、プーリング層1\n",
    "h_conv1 = tf.layers.conv2d(inputs=input_layer,filters=96,kernel_size=[11, 11],strides=(4,4),padding='same',activation=tf.nn.relu)\n",
    "h_norm1 = tf.nn.local_response_normalization(h_conv1,depth_radius=2,alpha=2e-5,beta=0.75)\n",
    "h_pool1 = tf.layers.max_pooling2d(inputs=h_norm1,pool_size=(3,3),strides=(2,2),padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"LRN_1:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 14, 14, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### 畳込み層、プーリング層2\n",
    "h_conv2 = tf.layers.conv2d(inputs=h_pool1,filters=256,kernel_size=[5, 5],padding='same',activation=tf.nn.relu)\n",
    "h_norm2 = tf.nn.local_response_normalization(h_conv2,depth_radius=2,alpha=2e-5,beta=0.75)\n",
    "h_pool2 = tf.layers.max_pooling2d(inputs=h_norm2,pool_size=(3,3),strides=(2,2),padding='same')\n",
    "print(h_norm2)\n",
    "print(h_pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_5/Relu:0\", shape=(?, 14, 14, 256), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"Reshape_3:0\", shape=(?, 2304), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(?, 9216), dtype=float32)\n",
      "Tensor(\"concat:0\", shape=(?, 12800), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### 畳込み層、プーリング層3\n",
    "h_conv3_1 = tf.layers.conv2d(inputs=h_pool2,filters=384,kernel_size=[3, 3],padding='same',activation=tf.nn.relu)\n",
    "h_conv3_2 = tf.layers.conv2d(inputs=h_conv3_1,filters=384,kernel_size=[3, 3],padding='same',activation=tf.nn.relu)\n",
    "h_conv3_3 = tf.layers.conv2d(inputs=h_conv3_2,filters=256,kernel_size=[3, 3],padding='same',activation=tf.nn.relu)\n",
    "\n",
    "h_pool3_1 = tf.layers.max_pooling2d(inputs=h_conv3_3,pool_size=(14,14),strides=(2,2),padding='valid')\n",
    "h_pool3_2 = tf.layers.max_pooling2d(inputs=h_conv3_3,pool_size=(12,12),strides=(2,2),padding='valid')\n",
    "h_pool3_3 = tf.layers.max_pooling2d(inputs=h_conv3_3,pool_size=(9,9),strides=(2,2),padding='valid')\n",
    "h_pool3_4 = tf.layers.max_pooling2d(inputs=h_conv3_3,pool_size=(4,4),strides=(2,2),padding='valid')\n",
    "h_pool3_1_flat = tf.reshape(h_pool3_1,[-1,1*1*256])\n",
    "h_pool3_2_flat = tf.reshape(h_pool3_2,[-1,2*2*256])\n",
    "h_pool3_3_flat = tf.reshape(h_pool3_3,[-1,3*3*256])\n",
    "h_pool3_4_flat = tf.reshape(h_pool3_4,[-1,6*6*256])\n",
    "\n",
    "print(h_conv3_3)\n",
    "print(h_pool3_1_flat)\n",
    "print(h_pool3_2_flat)\n",
    "print(h_pool3_3_flat)\n",
    "print(h_pool3_4_flat)\n",
    "\n",
    "h_spp = tf.concat([h_pool3_1_flat, h_pool3_2_flat, h_pool3_3_flat, h_pool3_4_flat],axis=1)\n",
    "print(h_spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 全結合層1\n",
    "\n",
    "stddev = np.sqrt(1.0 / 12800)\n",
    "h_W_fc1 = tf.Variable(tf.truncated_normal([12800,4096], stddev=stddev)) \n",
    "h_b_fc1 = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_spp, h_W_fc1) + h_b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 全結合層2\n",
    "\n",
    "stddev = np.sqrt(1.0 / 4096)\n",
    "h_W_fc2 = tf.Variable(tf.truncated_normal([4096,4096], stddev=stddev)) \n",
    "h_b_fc2 = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, h_W_fc2) + h_b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 出力層\n",
    "stddev = np.sqrt(2.0 / 4096)\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([4096,4], stddev=stddev))\n",
    "b_fc3 = tf.Variable(tf.constant(0.1, shape=[4]))\n",
    "y_conv = tf.nn.xw_plus_b(h_fc2_drop,W_fc3,b_fc3,name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 損失\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=t, logits=y_conv))\n",
    "\n",
    "### 学習op\n",
    "optimizer = tf.train.AdamOptimizer(1e-5)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "### モデルの評価\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(t,1))\n",
    "# 精度\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] step: 0, loss: 1.354834, acc: 0.370900, [Test] acc : 0.405405\n",
      "Time : 35.224357\n",
      "[Train] step: 10, loss: 1.342921, acc: 0.273339, [Test] acc : 0.162162\n",
      "Time : 89.294784\n",
      "[Train] step: 20, loss: 1.315431, acc: 0.370900, [Test] acc : 0.405405\n",
      "Time : 152.735984\n",
      "[Train] step: 30, loss: 1.296959, acc: 0.370900, [Test] acc : 0.405405\n",
      "Time : 211.458777\n",
      "[Train] step: 40, loss: 1.277008, acc: 0.370900, [Test] acc : 0.405405\n",
      "Time : 268.845662\n",
      "[Train] step: 50, loss: 1.231085, acc: 0.403701, [Test] acc : 0.405405\n",
      "Time : 323.676125\n",
      "[Train] step: 60, loss: 1.151875, acc: 0.506308, [Test] acc : 0.648649\n",
      "Time : 376.132766\n",
      "[Train] step: 70, loss: 1.058659, acc: 0.574432, [Test] acc : 0.648649\n",
      "Time : 441.771985\n",
      "[Train] step: 80, loss: 0.984500, acc: 0.513036, [Test] acc : 0.675676\n",
      "Time : 504.283124\n",
      "[Train] step: 90, loss: 0.932609, acc: 0.518923, [Test] acc : 0.648649\n",
      "Time : 564.317171\n",
      "[Train] step: 100, loss: 0.955021, acc: 0.532380, [Test] acc : 0.540541\n",
      "Time : 621.066628\n",
      "[Train] step: 110, loss: 0.871502, acc: 0.666947, [Test] acc : 0.756757\n",
      "Time : 678.373775\n",
      "[Train] step: 120, loss: 0.901933, acc: 0.523129, [Test] acc : 0.648649\n",
      "Time : 736.094705\n",
      "[Train] step: 130, loss: 0.819582, acc: 0.646762, [Test] acc : 0.783784\n",
      "Time : 790.113308\n",
      "[Train] step: 140, loss: 0.802311, acc: 0.640034, [Test] acc : 0.702703\n",
      "Time : 844.846585\n",
      "[Train] step: 150, loss: 0.785071, acc: 0.677881, [Test] acc : 0.756757\n",
      "Time : 898.728591\n",
      "[Train] step: 160, loss: 0.801055, acc: 0.682927, [Test] acc : 0.675676\n",
      "Time : 954.761563\n",
      "[Train] step: 170, loss: 0.745126, acc: 0.678722, [Test] acc : 0.837838\n",
      "Time : 1008.637016\n",
      "[Train] step: 180, loss: 0.725955, acc: 0.686291, [Test] acc : 0.810811\n",
      "Time : 1062.490388\n",
      "[Train] step: 190, loss: 0.716970, acc: 0.690496, [Test] acc : 0.837838\n",
      "Time : 1116.101926\n",
      "[Train] step: 200, loss: 0.685360, acc: 0.701430, [Test] acc : 0.729730\n",
      "Time : 1169.982540\n",
      "[Train] step: 210, loss: 0.700217, acc: 0.676198, [Test] acc : 0.756757\n",
      "Time : 1222.993909\n",
      "[Train] step: 220, loss: 0.695170, acc: 0.698066, [Test] acc : 0.810811\n",
      "Time : 1276.974340\n",
      "[Train] step: 230, loss: 0.679554, acc: 0.687973, [Test] acc : 0.756757\n",
      "Time : 1330.635289\n",
      "[Train] step: 240, loss: 0.638342, acc: 0.735913, [Test] acc : 0.648649\n",
      "Time : 1384.246175\n",
      "[Train] step: 250, loss: 0.612481, acc: 0.724979, [Test] acc : 0.702703\n",
      "Time : 1438.262511\n",
      "[Train] step: 260, loss: 0.587458, acc: 0.753574, [Test] acc : 0.729730\n",
      "Time : 1491.870976\n",
      "[Train] step: 270, loss: 0.590197, acc: 0.765349, [Test] acc : 0.675676\n",
      "Time : 1545.550329\n",
      "[Train] step: 280, loss: 0.574813, acc: 0.757780, [Test] acc : 0.621622\n",
      "Time : 1599.391562\n",
      "[Train] step: 290, loss: 0.570991, acc: 0.746005, [Test] acc : 0.810811\n",
      "Time : 1653.328851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./RoadSign-Alexnet-spp-ckpt/roadsign_alex_spp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 30\n",
    "start = time.time()\n",
    "for i in range(300):\n",
    "    batch_mask = np.random.choice(x_train.shape[0], batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    sess.run(train_step,feed_dict={X: x_batch, t: t_batch,keep_prob:0.5})\n",
    "    if i % 10 == 0:\n",
    "        train_acc, train_loss = sess.run([accuracy,loss], feed_dict={X: x_train, t: t_train,keep_prob:1.0})\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: x_test, t: t_test,keep_prob:1.0})\n",
    "        print(\"[Train] step: %d, loss: %f, acc: %f, [Test] acc : %f\" % (i, train_loss, train_acc,test_acc))\n",
    "        print(\"Time : %f\" % (time.time() - start))\n",
    "        \n",
    "saver.save(sess, \"./RoadSign-Alexnet-spp-ckpt/roadsign_alex_spp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ./RoadSign-Alexnet-spp-ckpt/roadsign_alex_spp\n",
      "INFO:tensorflow:Restoring parameters from ./RoadSign-Alexnet-spp-ckpt/roadsign_alex_spp\n",
      "[Train] step: 0, loss: 0.551279, acc: 0.757780, [Test] acc : 0.837838\n",
      "Time : 35.775541\n",
      "[Train] step: 20, loss: 0.516316, acc: 0.777124, [Test] acc : 0.837838\n",
      "Time : 129.885311\n",
      "[Train] step: 40, loss: 0.497363, acc: 0.783852, [Test] acc : 0.729730\n",
      "Time : 216.746541\n",
      "[Train] step: 60, loss: 0.489088, acc: 0.787216, [Test] acc : 0.729730\n",
      "Time : 306.049734\n",
      "[Train] step: 80, loss: 0.477144, acc: 0.804037, [Test] acc : 0.675676\n",
      "Time : 396.907464\n",
      "[Train] step: 100, loss: 0.418703, acc: 0.816653, [Test] acc : 0.729730\n",
      "Time : 485.095378\n",
      "[Train] step: 120, loss: 0.498485, acc: 0.793944, [Test] acc : 0.621622\n",
      "Time : 571.354650\n",
      "[Train] step: 140, loss: 0.456117, acc: 0.788898, [Test] acc : 0.837838\n",
      "Time : 656.997699\n",
      "[Train] step: 160, loss: 0.355467, acc: 0.847771, [Test] acc : 0.810811\n",
      "Time : 737.250022\n",
      "[Train] step: 180, loss: 0.441363, acc: 0.804037, [Test] acc : 0.675676\n",
      "Time : 817.791865\n",
      "[Train] step: 200, loss: 0.343585, acc: 0.852817, [Test] acc : 0.837838\n",
      "Time : 898.325376\n",
      "[Train] step: 220, loss: 0.326793, acc: 0.861228, [Test] acc : 0.864865\n",
      "Time : 978.956063\n",
      "[Train] step: 240, loss: 0.284473, acc: 0.879731, [Test] acc : 0.756757\n",
      "Time : 1059.275433\n",
      "[Train] step: 260, loss: 0.283630, acc: 0.892347, [Test] acc : 0.756757\n",
      "Time : 1149.496726\n",
      "[Train] step: 280, loss: 0.330057, acc: 0.867115, [Test] acc : 0.594595\n",
      "Time : 1236.674215\n",
      "[Train] step: 300, loss: 0.259816, acc: 0.905803, [Test] acc : 0.729730\n",
      "Time : 1317.723915\n",
      "[Train] step: 320, loss: 0.336120, acc: 0.862910, [Test] acc : 0.891892\n",
      "Time : 1405.399011\n",
      "[Train] step: 340, loss: 0.207155, acc: 0.941968, [Test] acc : 0.864865\n",
      "Time : 1495.244134\n",
      "[Train] step: 360, loss: 0.209565, acc: 0.933558, [Test] acc : 0.864865\n",
      "Time : 1587.694074\n",
      "[Train] step: 380, loss: 0.173041, acc: 0.942809, [Test] acc : 0.891892\n",
      "Time : 1679.027303\n",
      "[Train] step: 400, loss: 0.175481, acc: 0.931876, [Test] acc : 0.891892\n",
      "Time : 1769.230517\n",
      "[Train] step: 420, loss: 0.172881, acc: 0.937763, [Test] acc : 0.891892\n",
      "Time : 1860.283264\n",
      "[Train] step: 440, loss: 0.166494, acc: 0.929352, [Test] acc : 0.918919\n",
      "Time : 1948.776082\n",
      "[Train] step: 460, loss: 0.135650, acc: 0.956266, [Test] acc : 0.891892\n",
      "Time : 2045.179382\n",
      "[Train] step: 480, loss: 0.205780, acc: 0.908326, [Test] acc : 0.918919\n",
      "Time : 2131.363304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./RoadSign-Alexnet-spp-ckpt2/roadsign_alex_spp'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.get_checkpoint_state('./RoadSign-Alexnet-spp-ckpt')\n",
    "if ckpt:\n",
    "    # checkpointファイルから最後に保存したモデルへのパスを取得する\n",
    "    last_model = ckpt.model_checkpoint_path\n",
    "    print(\"load {0}\".format(last_model))\n",
    "    # 学習済みモデルを読み込む\n",
    "    saver.restore(sess, last_model)\n",
    "\n",
    "batch_size = 30\n",
    "start = time.time()\n",
    "for i in range(500):\n",
    "    batch_mask = np.random.choice(x_train.shape[0], batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    sess.run(train_step,feed_dict={X: x_batch, t: t_batch,keep_prob:0.5})\n",
    "    if i % 20 == 0:\n",
    "        train_acc, train_loss = sess.run([accuracy,loss], feed_dict={X: x_train, t: t_train,keep_prob:1.0})\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: x_test, t: t_test,keep_prob:1.0})\n",
    "        print(\"[Train] step: %d, loss: %f, acc: %f, [Test] acc : %f\" % (i, train_loss, train_acc,test_acc))\n",
    "        print(\"Time : %f\" % (time.time() - start))\n",
    "        \n",
    "saver.save(sess, \"./RoadSign-Alexnet-spp-ckpt2/roadsign_alex_spp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
